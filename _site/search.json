[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Welcome to my space for Geospatial Analytics and Applications. Here, you’ll find projects and explorations that bring maps and data together to tell meaningful stories. My goal is to make geospatial concepts both practical and engaging, so anyone visiting can see the value of location-based thinking in everyday decisions."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Geospatial Analytics goes beyond maps! It is about working with data linked to real-world locations, importing, cleaning, combining, and analyzing it to uncover patterns and insights. In this Hands-on exercise, we will use R packages to work with spatial datasets and practice the full workflow of processing and exploring georeferenced information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#quarto",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#quarto",
    "title": "Hands on Exercise 01",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#running-code",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#running-code",
    "title": "Hands on Exercise 01",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands on Exercise 01",
    "section": "Install and launching R packages",
    "text": "Install and launching R packages\nThe code chunk below uses p_load() of pacman package to check if tidycerse packages are installed in the computer. If they are, they will be launched into R.\n\npacman::p_load(sf,tidyverse)\n\n##Data Acquistion\nData are key to data analytics including geospatial analytics. Hence, before analysing, we need to assemble the necessary data. In this hands-on exercise, you are required to extract the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb\n\n##Importing the Geospatial data\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n##Importing polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4651 features and 19 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11721.1 ymin: 27550.13 xmax: 42809.37 ymax: 49702.59\nProjected CRS: SVY21\n\n\n##Importing GIS data in kml format\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n##Checking the Content of A Simple Feature Data Frame\nPrior to wrangle the geospatial data, it is always a good practice for us to know more about the data sets first.\n###Working with st_geometry()\nThe column in the sf data.frame that contains the geometries is a list of class sfc. We can retrieve the geometry list-column in this case by mpsz$geom or mpsz[[1]], but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n##Working with glimpse()\nBeside the basic geospatial feature information, we also would like to learn more about the associated attribute information in the data frame. This is the time you will find glimpse() of dplyr. very handy as shown in the code chunk below.\n\n\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n##Working with head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n##Plotting the Geospatial Data\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. This is the time you will find plot() of R Graphic comes in very handy as shown in the code chunk below.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\nNow, let us plot the preschool layer ontop of the mpsz layer by using the code chunk below.\n\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), \n     add = TRUE)\n\n\n\n\n\n\n\n\n##Working with Projection\n###Assigning EPSG code to a simple feature data frame\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n##Transforming the projection of preschool from wgs84 to svy21.\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\nGeometry set for 2290 features  Geometry type: POINT Dimension:     XYZ Bounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134 z_range:       zmin: 0 zmax: 0 Geodetic CRS:  WGS 84 First 5 geometries:\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool &lt;- st_transform(preschool, \n                              crs = 3414)\n\nNext, let us display the content of preschool sf data frame as shown below.\nGeometry set for 2290 features  Geometry type: POINT Dimension:     XYZ Bounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88 z_range:       zmin: 0 zmax: 0 Projected CRS: SVY21 / Singapore TM First 5 geometries:\nNotice that it is in svy21 projected coordinate system now. Furthermore, if you refer to Bounding box:, the values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems.\nNow, let us try to plot the preschool layer ontop of mpsz layer again by using the similar code chunk you used earlier.\n\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), add = TRUE)\n\n\n\n\n\n\n\n\n##Importing and Converting An Aspatial Data\nIn practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, you will learn how to import an aspatial data into R environment and save it as a tibble data frame. Next, you will convert it into a simple feature data frame.\nFor the purpose of this exercise, the listings.csv data downloaded from AirBnb will be used.\n\n\n###Importing the aspatial data\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.After importing the data file into R, it is important for us to examine if the data file has been imported correctly.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3659 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (42): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe code chunk below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,659 × 79\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.03e13 2025-06-26   city … Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.03e13 2025-06-27   previ… B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.03e13 2025-06-27   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.03e13 2025-06-26   previ… 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.03e13 2025-06-27   previ… 15 m… Lovely hom…\n 6 294281 https://www.airbnb.co…   2.03e13 2025-06-30   city … 5 mi… I have 3 b…\n 7 324945 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Comf… **IMPORTAN…\n 8 330095 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Rela… **IMPORTAN…\n 9 344803 https://www.airbnb.co…   2.03e13 2025-06-25   city … Budg… Direct bus…\n10 369141 https://www.airbnb.co…   2.03e13 2025-06-26   city … 5min… A room in …\n# ℹ 3,649 more rows\n# ℹ 72 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\n##Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,659\nColumns: 78\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.025063e+13, 2.025063e+1…\n$ last_scraped                                 &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ source                                       &lt;chr&gt; \"city scrape\", \"previous …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 59, 59, 7, 59, 5…\n$ host_total_listings_count                    &lt;dbl&gt; 10, 10, 10, 88, 88, 8, 88…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 2, 1, 2, 1, 1, 2, 1, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; 1.0, NA, 0.5, NA, NA, 1.0…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, NA, 1, NA, NA, 2, NA, …\n$ beds                                         &lt;dbl&gt; 3, NA, 2, NA, NA, 1, NA, …\n$ amenities                                    &lt;chr&gt; \"[\\\"Shampoo\\\", \\\"Fire pit…\n$ price                                        &lt;chr&gt; \"$143.00\", NA, \"$76.00\", …\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 20, 30, 0, 0, 30, 0, …\n$ availability_60                              &lt;dbl&gt; 60, 49, 60, 24, 25, 60, 2…\n$ availability_90                              &lt;dbl&gt; 90, 79, 90, 54, 55, 90, 5…\n$ availability_365                             &lt;dbl&gt; 90, 79, 90, 153, 153, 365…\n$ calendar_last_scraped                        &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 131, …\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ availability_eoy                             &lt;dbl&gt; 90, 79, 90, 153, 153, 185…\n$ number_of_reviews_ly                         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_occupancy_l365d                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_revenue_l365d                      &lt;dbl&gt; 0, NA, 0, NA, NA, 0, NA, …\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 58, 58, 7, 58, 5…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 58, 58, 6, 58, 5…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.14, 0.27, 0.13, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands on Exercise 01",
    "section": "",
    "text": "Geospatial Data Science is about working with data connected to real-world locations—importing, cleaning, combining, and analyzing it to uncover patterns and insights. In this module, we shall get hands-on with spatial datasets in R, using the sf package to practice the entire workflow of processing and exploring georeferenced information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "##Geoprocessing with sf package",
    "text": "##Geoprocessing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, you will learn how to answer GIS questions by using geoprocessing functions of sf package.\n###Use case 1: Land acquisition analysis\n####The scenario\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\n####The solution\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(\n  cyclingpath, dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nIf you are tidyverse person like me, code chunk below should be used.\n\nbuffer_cycling &lt;- buffer_cycling %&gt;%\n  mutate(AREA = st_area(geometry))\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\n\nmpsz_selected &lt;- mpsz %&gt;%\n  filter(SUBZONE_N == \"TAMPINES WEST\") \n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\n\n\n#buffer_cycling_selected &lt;- st_intersection(\n # buffer_cycling, mpsz_selected)\n\n##Use case 2: To determine the number of pre-schools by planning subzone\n###The scenario\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n###The solution\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-import-polygon-feature-data-in-shapefile-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-import-polygon-feature-data-in-shapefile-format",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "4a) Import polygon feature data in shapefile format",
    "text": "4a) Import polygon feature data in shapefile format\nThe code chunk below uses st_read() function of sf package:\n\nto read simple features form file/database\nimports MP14_SUBZONE_WEB_PL shapefile into R as polygon feature data frame\ndsn = defines data path and layer = provide the shapefile name\n\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nObservation\n\n323 subzones represented as multipolygons with 15 attributes.\n\nUses SVY21 CRS for accurate distance and area measures.\n\nBounding box confirms full Singapore coverage."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#b-importing-polyline-feature-data-in-shapefile-form",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#b-importing-polyline-feature-data-in-shapefile-form",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "4b) Importing polyline feature data in shapefile form",
    "text": "4b) Importing polyline feature data in shapefile form\nThe code chunk below imports CyclingPath shapefile into R as line{.underline} feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4651 features and 19 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11721.1 ymin: 27550.13 xmax: 42809.37 ymax: 49702.59\nProjected CRS: SVY21\n\n\n\nObservation\n\nContains 4,651 cycling path features stored as multilines{.underline} with 19 attributes.\n\nCaptures the network of cycling paths across Singapore within the SVY21 CRS.\n\nBounding box shows the dataset spans the country’s extent."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#c-importing-gis-data-in-kml-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#c-importing-gis-data-in-kml-format",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "4c) Importing GIS data in kml format",
    "text": "4c) Importing GIS data in kml format\nThe PreSchoolsLocationis in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nObservation\n\nDataset contains 2,290 preschool locations stored as points{.underline} with 2 attributes.\n\nStored in WGS 84 CRS, suitable for global latitude–longitude mapping."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Geospatial Analytics goes beyond maps! It is about working with data linked to real-world locations, importing, cleaning, combining, and analyzing it to uncover patterns and insights. In this Hands-on exercise, we will use R packages to work with spatial datasets and practice the full workflow of processing and exploring georeferenced information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-import-polygon-feature-data-in-shapefile-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-import-polygon-feature-data-in-shapefile-format",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "4a) Import polygon feature data in shapefile format",
    "text": "4a) Import polygon feature data in shapefile format\nThe code chunk below uses st_read() function of sf package:\n\nto read simple features form file/database\nimports MP14_SUBZONE_WEB_PL shapefile into R as polygon feature data frame\ndsn = defines data path and layer = provide the shapefile name\n\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nObservations\n\n323 subzones represented as multipolygons with 15 attributes.\n\nUses SVY21 CRS for accurate distance and area measures.\n\nBounding box confirms full Singapore coverage."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-importing-polyline-feature-data-in-shapefile-form",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-importing-polyline-feature-data-in-shapefile-form",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "4b) Importing polyline feature data in shapefile form",
    "text": "4b) Importing polyline feature data in shapefile form\nThe code chunk below imports CyclingPath shapefile into R as line{.underline} feature data frame.\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4651 features and 19 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11721.1 ymin: 27550.13 xmax: 42809.37 ymax: 49702.59\nProjected CRS: SVY21\n\n\n\nObservations\n\nContains 4,651 cycling path features stored as multilines{.underline} with 19 attributes.\n\nCaptures the network of cycling paths across Singapore within the SVY21 CRS.\n\nBounding box shows the dataset spans the country’s extent."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#c-importing-gis-data-in-kml-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#c-importing-gis-data-in-kml-format",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "4c) Importing GIS data in kml format",
    "text": "4c) Importing GIS data in kml format\nThe PreSchoolsLocationis in kml format. The code chunk below will be used to import the kml into R.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nObservations\n\nDataset contains 2,290 preschool locations stored as points{.underline} with 2 attributes.\n\nStored in WGS 84 CRS, suitable for global latitude–longitude mapping."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#geoprocessing-with-sf-package",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "##Geoprocessing with sf package",
    "text": "##Geoprocessing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions.\nIn this section, you will learn how to answer GIS questions by using geoprocessing functions of sf package.\n###Use case 1: Land acquisition analysis\n####The scenario\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\n####The solution\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(\n  cyclingpath, dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nIf you are tidyverse person like me, code chunk below should be used.\n\nbuffer_cycling &lt;- buffer_cycling %&gt;%\n  mutate(AREA = st_area(geometry))\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\n\nmpsz_selected &lt;- mpsz %&gt;%\n  filter(SUBZONE_N == \"TAMPINES WEST\") \n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\n\n\n#buffer_cycling_selected &lt;- st_intersection(\n # buffer_cycling, mpsz_selected)\n\n##Use case 2: To determine the number of pre-schools by planning subzone\n###The scenario\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n###The solution\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-working-with-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-working-with-st_geometry",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "5a) Working with st_geometry()",
    "text": "5a) Working with st_geometry()\n\nIn a sf data frame, the geometry column is a list-column of class sfc.\nWe can access it directly with mpsz$geom or mpsz[[1]].\nThe general recommended way is st_geometry(mpsz)\n\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-working-with-glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-working-with-glimpse",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "5b) Working with glimpse()",
    "text": "5b) Working with glimpse()\n\nBeyond basic geometry, we often need to inspect the attribute columns in the sf data frame.\nIt’s handy for quickly understanding structure, spotting odd types or missing values, and confirming row/column counts.\n\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#c-working-with-head",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#c-working-with-head",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "5c) Working with head()",
    "text": "5c) Working with head()\n\nhead() displays the top rows of a data frame.\nThe argument n sets how many rows to show (e.g., head(mpsz, n = 5 or 10)).\n\n\nhead(mpsz, n=10)\n\nSimple feature collection with 10 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 20660.53 ymin: 28369.47 xmax: 32362.39 ymax: 30684.55\nProjected CRS: SVY21\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "7a) Assigning EPSG code to a simple feature data frame",
    "text": "7a) Assigning EPSG code to a simple feature data frame\nA common issue during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\nWe sense that the EPSG code is indicated as 9001 which is incorrect,Although mpsz data frame is projected in svy21 and the correct EPSG code for svy21 should be 3414\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nIn order to assign the correct EPSG code to mpsz data frame,we use st_set_crs() of sf package.\n\nmpsz &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nLet us check the CSR again.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "7b) Transforming the projection of preschool from wgs84 to svy21",
    "text": "7b) Transforming the projection of preschool from wgs84 to svy21\nIn geospatial analytics, it is common for us to transform the original data from geographic coordinate system to projected coordinate system as geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool &lt;- st_transform(preschool, \n                              crs = 3414)\n\nLet us try to plot the preschool layer ontop of mpsz layer again.\n\npar(bg = '#fffbe8')\nplot(st_geometry(mpsz))\nplot(st_geometry(preschool), add = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-importing-the-aspatial-data",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "8a) Importing the aspatial data",
    "text": "8a) Importing the aspatial data\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3659 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (42): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.We use list() instead of glimpse()\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,659 × 79\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.03e13 2025-06-26   city … Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.03e13 2025-06-27   previ… B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.03e13 2025-06-27   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.03e13 2025-06-26   previ… 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.03e13 2025-06-27   previ… 15 m… Lovely hom…\n 6 294281 https://www.airbnb.co…   2.03e13 2025-06-30   city … 5 mi… I have 3 b…\n 7 324945 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Comf… **IMPORTAN…\n 8 330095 https://www.airbnb.co…   2.03e13 2025-06-27   previ… Rela… **IMPORTAN…\n 9 344803 https://www.airbnb.co…   2.03e13 2025-06-25   city … Budg… Direct bus…\n10 369141 https://www.airbnb.co…   2.03e13 2025-06-26   city … 5min… A room in …\n# ℹ 3,649 more rows\n# ℹ 72 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "8b) Creating a simple feature data frame from an aspatial data frame",
    "text": "8b) Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nArguments:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,659\nColumns: 78\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.025063e+13, 2.025063e+1…\n$ last_scraped                                 &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ source                                       &lt;chr&gt; \"city scrape\", \"previous …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 59, 59, 7, 59, 5…\n$ host_total_listings_count                    &lt;dbl&gt; 10, 10, 10, 88, 88, 8, 88…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 2, 1, 2, 1, 1, 2, 1, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; 1.0, NA, 0.5, NA, NA, 1.0…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, NA, 1, NA, NA, 2, NA, …\n$ beds                                         &lt;dbl&gt; 3, NA, 2, NA, NA, 1, NA, …\n$ amenities                                    &lt;chr&gt; \"[\\\"Shampoo\\\", \\\"Fire pit…\n$ price                                        &lt;chr&gt; \"$143.00\", NA, \"$76.00\", …\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 20, 30, 0, 0, 30, 0, …\n$ availability_60                              &lt;dbl&gt; 60, 49, 60, 24, 25, 60, 2…\n$ availability_90                              &lt;dbl&gt; 90, 79, 90, 54, 55, 90, 5…\n$ availability_365                             &lt;dbl&gt; 90, 79, 90, 153, 153, 365…\n$ calendar_last_scraped                        &lt;date&gt; 2025-06-26, 2025-06-27, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 131, …\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ availability_eoy                             &lt;dbl&gt; 90, 79, 90, 153, 153, 185…\n$ number_of_reviews_ly                         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_occupancy_l365d                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ estimated_revenue_l365d                      &lt;dbl&gt; 0, NA, 0, NA, NA, 0, NA, …\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 58, 58, 7, 58, 5…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 58, 58, 6, 58, 5…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.14, 0.27, 0.13, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\n\nDIY: Using the method you learned earlier, plot listing_sf layer on top of mpsz layer.\n\n1) Make sure CRS matches (transform points to mpsz CRS)\n\nlistings_sf &lt;- st_transform(listings_sf, st_crs(mpsz))\n\n\n\n2) Plot: mpsz first, then listings on top\n\npar(bg = \"#fffbe8\")\nplot(st_geometry(mpsz), col = \"grey95\", border = \"grey60\", reset = FALSE)\nplot(st_geometry(listings_sf), pch = 16, cex = 0.5, col = \"#d1495b\", add = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#use-case-1-land-acquisition-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#use-case-1-land-acquisition-analysis",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "Use case 1: Land acquisition analysis**",
    "text": "Use case 1: Land acquisition analysis**\n####The scenario\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\n####The solution\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths.\n\nbuffer_cycling &lt;- st_buffer(\n  cyclingpath, dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nIf you are tidyverse person like me, code chunk below should be used.\n\nbuffer_cycling &lt;- buffer_cycling %&gt;%\n  mutate(AREA = st_area(geometry))\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\n\nmpsz_selected &lt;- mpsz %&gt;%\n  filter(SUBZONE_N == \"TAMPINES WEST\") \n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\n\n\n#buffer_cycling_selected &lt;- st_intersection(\n # buffer_cycling, mpsz_selected)\n\n##Use case 2: To determine the number of pre-schools by planning subzone\n###The scenario\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n###The solution\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-use-case-1-land-acquisition-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#a-use-case-1-land-acquisition-analysis",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "9a) Use case 1: Land acquisition analysis",
    "text": "9a) Use case 1: Land acquisition analysis\n\nThe scenario\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path.We are tasked to determine the extend of the land need to be acquired and their total area.\n\n\nThe solution\n9a.1  st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(  cyclingpath, dist=5, nQuadSegs = 30)\n\n9a.2 Followed by calculating the area of the buffers\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\n\nbuffer_cycling &lt;- buffer_cycling %&gt;%  mutate(AREA = st_area(geometry))\n\n9a.3 sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\n\nmpsz_selected &lt;- mpsz %&gt;%  filter(SUBZONE_N == \"TAMPINES WEST\") \n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\n\nbuffer_cycling &lt;- st_transform(buffer_cycling, st_crs(mpsz_selected))\nmpsz_selected &lt;- st_transform(mpsz_selected, st_crs(buffer_cycling))\nbuffer_cycling_selected &lt;- st_intersection(buffer_cycling, mpsz_selected)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nFinally, we plot the result\n\npar(bg = \"#fffbe8\")\nplot(st_geometry(mpsz_selected), col = \"lightgrey\", main = \"Buffer Zone in Tampines West\")\nplot(st_geometry(buffer_cycling_selected), col = \"#d1495b\", add = TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#the-scenario",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#the-scenario",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "The scenario",
    "text": "The scenario\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the existing cycling path.We are tasked to determine the extend of the land need to be acquired and their total area."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#the-solution",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#the-solution",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "The solution",
    "text": "The solution\n9a.1  st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths,\n\nbuffer_cycling &lt;- st_buffer(  cyclingpath, dist=5, nQuadSegs = 30)\n\n9a.2 Followed by calculating the area of the buffers.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\n\nbuffer_cycling &lt;- buffer_cycling %&gt;%  mutate(AREA = st_area(geometry))\n\n9a.3 sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n3561648 [m^2]\n\n\nWe can also create a plot showing the buffer by a selected planning subzone.\nAssuming that we are interested on the land acquisition in Tampines West planning subzone.\nFirstly, filter() of dplyr package will be used to extract polygon feature of Tampines West by using the code chunk below.\n\n\nmpsz_selected &lt;- mpsz %&gt;%  filter(SUBZONE_N == \"TAMPINES WEST\") \n\nNext, st_intersection() of sf package will be used to clip cycling buffers within Tampines West planning subzone.\n\nbuffer_cycling &lt;- st_transform(buffer_cycling, st_crs(mpsz_selected))\nmpsz_selected &lt;- st_transform(mpsz_selected, st_crs(buffer_cycling))\nbuffer_cycling_selected &lt;- st_intersection(buffer_cycling, mpsz_selected)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nFinally, we plot the result\n\nplot(st_geometry(mpsz_selected), col = \"lightgrey\", main = \"Buffer Zone in Tampines West\")\nplot(st_geometry(buffer_cycling_selected), col = \"#d1495b\", add = TRUE)\n\n\n\n\n\n\n\n\n##Use case 2: To determine the number of pre-schools by planning subzone\n###The scenario\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n###The solution\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))\n\n\nst_intersects() checks which points fall inside each polygon.\nlengths() counts how many pre-schools intersect each subzone.\n\n\n2: View summary statistics\n\nsummary(mpsz$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\n\nThis shows min, max, mean, and quartiles of pre-school counts.\n\n\n\n3: Find subzone with the most pre-schools\n\ntop_n(mpsz, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\ntop_n() returns the subzone with the highest count.\n\n\n\n4: Calculate area of each subzone\n\nmpsz$Area &lt;- st_area(mpsz)\n\n\nAdds a new column Area with the size of each subzone in square meters.\n\n\n\n5: Compute pre-school density\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(`PreSch Density` = `PreSch Count` / Area * 1e6)\n\n\nConverts count per square meter to count per square kilometer.\n\n\n\n6: Visualize Pre-School Density\nA. Histogram using base R\n\nhist(mpsz$`PreSch Density`)\n\n\n\n\n\n\n\n\n\nQuick view of distribution, but limited styling.\n\nB. Histogram using ggplot2\n\nlibrary(ggplot2)\nggplot(data = mpsz, aes(x = as.numeric(`PreSch Density`))) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\") +\n  labs(\n    title = \"Are pre-schools evenly distributed in Singapore?\",\n    subtitle = \"Many subzones have only one pre-school, while seven have 30 or more.\",\n    x = \"Pre-school density (per km²)\",\n    y = \"Frequency\"\n  )\n\n\n\n\n\n\n\n\n\nA polished histogram with custom labels and colors.\n\n\n\n7: Scatterplot of Density vs Count\n\nggplot(data = mpsz, aes(x = as.numeric(`PreSch Density`), y = `PreSch Count`)) +\n  geom_point(color = \"black\", fill = \"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(\n    x = \"Pre-school density (per km²)\",\n    y = \"Pre-school count\"\n  )\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nShows the relationship between density and total count per subzone."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-use-case-2-to-determine-the-number-of-pre-schools-by-planning-subzone",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01a.html#b-use-case-2-to-determine-the-number-of-pre-schools-by-planning-subzone",
    "title": "Hands on Exercise 1a: Geospatial Data Wrangling with R",
    "section": "9b) Use case 2: To determine the number of pre-schools by planning subzone",
    "text": "9b) Use case 2: To determine the number of pre-schools by planning subzone\n\nThe scenario\nThe authority requires a count of pre-schools for each planning subzone to support forward planning. Using R and the sf package, perform the necessary geoprocessing to compute these counts and present the results clearly.\n\n\nThe solution\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz$`PreSch Count`&lt;- lengths(st_intersects(mpsz, preschool))\n\n\nst_intersects() checks which points fall inside each polygon.\nlengths() counts how many pre-schools intersect each subzone.\n\n9b.1 View summary statistics\n\nsummary(mpsz$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\n\nThis shows min, max, mean, and quartiles of pre-school counts.\n\n9b.2 Find subzone with the most pre-schools\n\ntop_n(mpsz, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\ntop_n() returns the subzone with the highest count.\n\n9b.3 Calculate area of each subzone\n\nmpsz$Area &lt;- st_area(mpsz)\n\n\nAdds a new column Area with the size of each subzone in square meters.\n\n9b.4 Compute pre-school density\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(`PreSch Density` = `PreSch Count` / Area * 1e6)\n\n\nConverts count per square meter to count per square kilometer.\n\n9b.5 Visualize Pre-School Density\nHistogram using base R\n\nhist(mpsz$`PreSch Density`)\n\n\n\n\n\n\n\n\n\nQuick view of distribution, but limited styling.\n\nHistogram using ggplot2\n\nlibrary(ggplot2)\nggplot(data = mpsz, aes(x = as.numeric(`PreSch Density`))) +\n  geom_histogram(bins = 20, color = \"black\", fill = \"light blue\") +\n  labs(\n    title = \"Are pre-schools evenly distributed in Singapore?\",\n    subtitle = \"Many subzones have only one pre-school, while seven have 30 or more.\",\n    x = \"Pre-school density (per km²)\",\n    y = \"Frequency\"\n  )\n\n\n\n\n\n\n\n\n\nA polished histogram with custom labels and colors.\n\n9b.6 Scatterplot of Density vs Count\n\nggplot(data = mpsz, aes(x = as.numeric(`PreSch Density`), y = `PreSch Count`)) +\n  geom_point(color = \"black\", fill = \"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(\n    x = \"Pre-school density (per km²)\",\n    y = \"Pre-school count\"\n  )\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\nShows the relationship between density and total count per subzone."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Thematic mapping involves the use of map symbols to visualize selected properties of geographic features that are not naturally visible, such as population, temperature, crime rate, and property prices, just to mention a few of them.\nGeovisualisation, on the other hand, is the process of using visual representations and cartographic techniques to explore, analyze, and communicate geospatial data. It combines elements of cartography, computer science, and information visualization to enhance spatial understanding and knowledge discovery.\nA choropleth map colors areas (e.g., planning subzones) based on a number so we can spot patterns quickly darker usually means higher values. To keep it truthful, let us map rates or densities (not raw counts), pick sensible class breaks, use a clear sequential palette, and include a readable legend and title with a consistent projection.\nLet us use the tmap package in R to build functional choropleths by adjusting styles and palettes while checking CRS and missing values so the story stays accurate."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#a-importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#a-importing-geospatial-data-into-r",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "3a) Importing Geospatial Data into R",
    "text": "3a) Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(\"data/geospatial/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nCreate a helper function to extract values from the HTML description\n\nextract_kml_field &lt;- function(html_text, field_name) {   \n  if (is.na(html_text) || html_text == \"\") return(NA_character_)      \n  page &lt;- read_html(html_text)  \n  rows &lt;- page %&gt;% html_elements(\"tr\")    \n  value &lt;- rows %&gt;%     \n    keep(~ html_text2(html_element(.x, \"th\")) == field_name) %&gt;%    \n    html_element(\"td\") %&gt;%    \n    html_text2()     \n  if (length(value) == 0) NA_character_ else value }\n\nApplying the function created and extracting the relevant fields , then adding 4 columns to mpsz.\n\nmpsz &lt;- mpsz %&gt;%\n  mutate(\n    REGION_N = map_chr(Description, extract_kml_field, \"REGION_N\"),\n    PLN_AREA_N = map_chr(Description, extract_kml_field, \"PLN_AREA_N\"),\n    SUBZONE_N = map_chr(Description, extract_kml_field, \"SUBZONE_N\"),\n    SUBZONE_C = map_chr(Description, extract_kml_field, \"SUBZONE_C\")\n  ) %&gt;%\n  select(-Name, -Description) %&gt;%\n  relocate(geometry, .after = last_col())\n\n\nmpsz\n\nSimple feature collection with 332 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\nFirst 10 features:\n         REGION_N    PLN_AREA_N           SUBZONE_N SUBZONE_C\n1  CENTRAL REGION   BUKIT MERAH          DEPOT ROAD    BMSZ12\n2  CENTRAL REGION   BUKIT MERAH         BUKIT MERAH    BMSZ02\n3  CENTRAL REGION        OUTRAM           CHINATOWN    OTSZ03\n4  CENTRAL REGION DOWNTOWN CORE             PHILLIP    DTSZ04\n5  CENTRAL REGION DOWNTOWN CORE       RAFFLES PLACE    DTSZ05\n6  CENTRAL REGION        OUTRAM        CHINA SQUARE    OTSZ04\n7  CENTRAL REGION   BUKIT MERAH         TIONG BAHRU    BMSZ10\n8  CENTRAL REGION DOWNTOWN CORE    BAYFRONT SUBZONE    DTSZ12\n9  CENTRAL REGION   BUKIT MERAH TIONG BAHRU STATION    BMSZ04\n10 CENTRAL REGION DOWNTOWN CORE       CLIFFORD PIER    DTSZ06\n                         geometry\n1  MULTIPOLYGON (((103.8145 1....\n2  MULTIPOLYGON (((103.8221 1....\n3  MULTIPOLYGON (((103.8438 1....\n4  MULTIPOLYGON (((103.8496 1....\n5  MULTIPOLYGON (((103.8525 1....\n6  MULTIPOLYGON (((103.8486 1....\n7  MULTIPOLYGON (((103.8311 1....\n8  MULTIPOLYGON (((103.8589 1....\n9  MULTIPOLYGON (((103.8283 1....\n10 MULTIPOLYGON (((103.8552 1....\n\n\n\nObservations Notice that only the first ten records will be displayed. Do you know why?\nWe could view only the first 10 records because sf/tibble prints a short preview by default. R truncates to the first 10 features to keep the console tidy and fast.Nothing is wrong with the data. To see more, increase n (e.g., print(st_geometry(mpsz), n = 50) or print(mpsz, n = Inf)) or use head(mpsz, 20) / nrow(mpsz)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#b-importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#b-importing-attribute-data-into-r",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "3b) Importing Attribute Data into R",
    "text": "3b) Importing Attribute Data into R\nNext, we will import respopagesextod2024.csv file into RStudio and save the file into an tibble dataframe called popdata.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2024.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#a-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#a-data-wrangling",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "4a) Data wrangling",
    "text": "4a) Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2024 &lt;- popdata %&gt;%   \n  group_by(PA, SZ, AG) %&gt;%   \n  summarise(`POP` = sum(`Pop`)) %&gt;%  \n  ungroup()%&gt;%  \n  pivot_wider(names_from=AG,             \n              values_from=POP) %&gt;%   \n  mutate(YOUNG = rowSums(.[3:6])      \n         +rowSums(.[12])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])\n         +rowSums(.[13:15]))%&gt;% \n  mutate(`AGED`=rowSums(.[16:21])) %&gt;% \n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n         /`ECONOMY ACTIVE`) %&gt;%   \n  select(`PA`, `SZ`, `YOUNG`,         \n         `ECONOMY ACTIVE`, `AGED`,       \n         `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#b-joining-the-attribute-data-and-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#b-joining-the-attribute-data-and-geospatial-data",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "4b) Joining the attribute data and geospatial data",
    "text": "4b) Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2024 &lt;- popdata2024 %&gt;%   \n  mutate_at(.vars = vars(PA, SZ),         \n            .funs = list(toupper)) %&gt;%   \n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2024 &lt;- left_join(mpsz, popdata2024,by = c(\"SUBZONE_N\" = \"SZ\"))\n\nWe can save the Joined data and learn from the code chunk above:\n\ndir.create(\"data/rds\", recursive = TRUE, showWarnings = FALSE)\nwrite_rds(mpsz_pop2024, \"data/rds/mpsz_pop2024.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#a-plotting-a-choropleth-map-quickly-by-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#a-plotting-a-choropleth-map-quickly-by-using-qtm",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "5a) Plotting a choropleth map quickly by using qtm()",
    "text": "5a) Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm().\n\npar(bg = '#fffbe8')\ntmap_mode(\"plot\") \n\nℹ tmap mode set to \"plot\".\n\nqtm(shp = mpsz_pop2024, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#b-creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#b-creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "5b) Creating a choropleth map by using tmap’s elements",
    "text": "5b) Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control.\n\ntm_shape(mpsz_pop2024) +   \n  tm_polygons(fill = \"DEPENDENCY\",      \n              fill.scale = tm_scale_intervals(  \n                style = \"quantile\",          \n                n = 5,            \n                values = \"brewer.blues\"), \n              fill.legend = tm_legend(     \n                title = \"Dependency ratio\")) + \n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") + \n  tm_layout(frame = TRUE) +   tm_borders(fill_alpha = 0.5) + \n  tm_compass(type=\"8star\", size = 2) +   \n  tm_scalebar() + \n  tm_grid(alpha =0.2) +   \n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",       \n             position = c(\"left\", \"bottom\"))\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\n\n5b.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_polygons(), tm_symbols(), tm_lines(), tm_raster() and tm_text().\n’tm_shape()is used to define the input data (i.e *mpsz_pop2024*) andtm_polygons()` is used to draw the planning subzone polygons\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +  \n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n5b.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024)+\n  tm_polygons(fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nBy using tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”\nThe default colour scheme used is blues3 of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\n5b.3 Drawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the polygon features onto the choropleth map.\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nAdding tm_borders()\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders()\n\n\n\n\n\n\n\n\nCustomising tm_borders(),\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(col = \"grey60\",\n             lwd = 0.1,\n             lty = \"dashed\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#c-data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#c-data-classification-methods-of-tmap",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "5c) Data classification methods of tmap",
    "text": "5c) Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\n5c.1 Plotting choropleth maps with built-in classification methods\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\n\n\n5c.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_scale_intervals(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started,explore the data.\n\npar(bg = '#fffbe8')\nsummary(mpsz_pop2024$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1905  0.7450  0.8377  0.8738  0.9366 12.7500      94 \n\n\n Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's   0.1905  0.7450  0.8377  0.8738  0.9366 12.7500      94 \nPlotting the custom breaks\n\ntm_shape(mpsz_pop2024)+\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00))) +\n  tm_borders(fill_alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break. They are\nassigned to the highest interval"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#d-colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#d-colour-scheme",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "5d) Colour Scheme",
    "text": "5d) Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n5d.1 Using ColourBrewer palette\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n5d.2 Cartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar(), tm_grid() and tm_credit() are used to add compass, scale bar, grid lines and data sources onto the choropleth map.\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5)) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: data.gov.sg & singstat\",\n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#e-map-layout",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#e-map-layout",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "5e) Map Layout",
    "text": "5e) Map Layout\nMap layout refers to the combination of all map elements into a cohensive map. It includes the map background, frame, typography, scale, aspect ratio, margins, and more.\nWe can customize the map layout using the tm_layout() function.\n\n5e.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_pos_auto_in() +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scalebar() +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: data.gov.sg & singstat\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n5e.2 Map style\ntmap allows a wide variety of layout settings to be changed which are called using tmap_style().\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"-brewer.greens\")) + \n  tm_borders(fill_alpha = 0.5) + \n  tmap_style(\"natural\")\n\nstyle set to \"natural\"\n\n\nother available styles are: \"white\" (tmap default), \"gray\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\"\n\n\n\n\n\n\n\n\n\n\ntmap_style(\"white\")\n\nstyle set to \"white\" (tmap default)\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\"\n\n\n\n\n5e.3 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby creating multiple stand-alone maps with tmap_arrange(), and\nby defining a group-by variable in tm_facets().\n\n\n\n5e.4 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by assigning two variables to the visual variable (i.e. fill).\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) + \n  tm_polygons(\n    fill = c(\"YOUNG\", \"AGED\"),\n    fill.legend = \n      tm_legend(position = tm_pos_in(\n        \"right\", \"bottom\")),\n    fill.scale = tm_scale_intervals(\n      style = \"equal\", \n      n = 5,\n      values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tmap_style(\"natural\")\n\nstyle set to \"natural\"\n\n\nother available styles are: \"white\" (tmap default), \"gray\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\"\n\n\n\n\n\n\n\n\n\n\n\n5e.5 By arrange multiples choropleth maps in a grid layout\nIn this example, multiple choropleth maps are created and tmap_arrnage() is used to arrange them in a grid layout.\n\npar(bg = '#fffbe8')\nyoungmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"YOUNG\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                  item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of young population\")\n                \nagedmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"AGED\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n              style = \"quantile\", \n              values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of aged population\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n5e.6 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +\n  tm_fill(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\",\n            values = \"brewer.blues\")) + \n  tm_facets(by = \"REGION_N\",\n            nrow = 2, \n            ncols = 3,\n            free.coords=TRUE, \n            drop.units=TRUE) +\n  tm_layout(legend.show = TRUE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(fill_alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#e.4-drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#e.4-drawing-small-multiple-choropleth-maps",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "5e.4 Drawing Small Multiple Choropleth Maps**",
    "text": "5e.4 Drawing Small Multiple Choropleth Maps**\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby creating multiple stand-alone maps with tmap_arrange(), and\nby defining a group-by variable in tm_facets().\n\n\n2.5.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by assigning two variables to the visual variable (i.e. fill).\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) + \n  tm_polygons(\n    fill = c(\"YOUNG\", \"AGED\"),\n    fill.legend = \n      tm_legend(position = tm_pos_in(\n        \"right\", \"bottom\")),\n    fill.scale = tm_scale_intervals(\n      style = \"equal\", \n      n = 5,\n      values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tmap_style(\"natural\")\n\nstyle set to \"natural\"\n\n\nother available styles are: \"white\" (tmap default), \"gray\", \"cobalt\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\"\n\n\ntmap v3 styles: \"v3\" (tmap v3 default), \"gray_v3\", \"natural_v3\", \"cobalt_v3\", \"albatross_v3\", \"beaver_v3\", \"bw_v3\", \"classic_v3\", \"watercolor_v3\"\n\n\n\n\n\n\n\n\n\n\n\n2.5.2 By arrange multiples choropleth maps in a grid layout\nIn this example, multiple choropleth maps are created and tmap_arrnage() is used to arrnage them in a grid layout.\n\npar(bg = '#fffbe8')\nyoungmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"YOUNG\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                  item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of young population\")\n                \nagedmap &lt;- tm_shape(mpsz_pop2024)+ \n  tm_polygons(fill = \"AGED\",\n              fill.legend = tm_legend(\n                position = tm_pos_in(\n                  \"right\", \"bottom\"),\n                item.height = 0.8),\n              fill.scale = tm_scale_intervals(\n              style = \"quantile\", \n              values = \"brewer.blues\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of aged population\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n2.5.3 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\npar(bg = '#fffbe8')\ntm_shape(mpsz_pop2024) +\n  tm_fill(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\",\n            values = \"brewer.blues\")) + \n  tm_facets(by = \"REGION_N\",\n            nrow = 2, \n            ncols = 3,\n            free.coords=TRUE, \n            drop.units=TRUE) +\n  tm_layout(legend.show = TRUE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(fill_alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#f-mappping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#f-mappping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "5f) Mappping Spatial Object Meeting a Selection Criterion",
    "text": "5f) Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use filter() of dplyr package to select geographical area of interest and plot a choropleth map focus only on the selected region.\n\npar(bg = '#fffbe8')\nmpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\") %&gt;%\n  tm_shape() +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.greens\"),\n              fill.legend = tm_legend()) +\n  tm_borders(fill_alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#complementing-thematic-map-with-statistical-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#complementing-thematic-map-with-statistical-chart",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "2.7 Complementing Thematic Map with Statistical Chart",
    "text": "2.7 Complementing Thematic Map with Statistical Chart\nMaps and statistical charts complement each other by visually representing different aspects of the same data, offering a more comprehensive understanding. Maps excel at showing spatial relationships and geographical patterns, while charts effectively display numerical data, trends, and comparisons. Combining both allows for a more insightful and engaging data narrative, especially when dealing with spatial data that also has quantifiable characteristics.\nWith tmap, statistical chart and be incorporate into the map visualisation by using fill.chat argument of map layers and legend chart feature as shown in the code chunk below.\n\npar(bg = '#fffbe8')\nmpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\") %&gt;%\n  tm_shape() +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.greens\"),\n              fill.legend = tm_legend(),\n              fill.chart = tm_chart_box()) +\n  tm_borders() +\n  tm_layout(asp = 0.8)\n\n\n\n\n\n\n\n\nIn the code chunk below, We improve the visual representation further by highlighting and lebaling the outliers on the choropleth map.\n\npar(bg = '#fffbe8')\nmpsz_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\n\nstats &lt;- boxplot.stats(mpsz_selected$DEPENDENCY)\n\noutlier_vals &lt;- stats$out\n\noutlier_sf &lt;- mpsz_selected[mpsz_selected$DEPENDENCY %in% outlier_vals, ]\n\ntm_shape(mpsz_selected) +\n  tm_polygons(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\", \n            values = \"brewer.blues\"),\n          fill.legend = tm_legend(),\n          fill.chart = tm_chart_box()) +\n  tm_borders(fill_alpha = 0.5) +\ntm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2) +\n  tm_text(\"SUBZONE_N\", col = \"red\", size = 0.7) +\n  tm_layout(asp = 0.8)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#creating-interactive-map",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#creating-interactive-map",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "2.8 Creating Interactive Map",
    "text": "2.8 Creating Interactive Map\nInteractive maps let users actively explore and interact with the data they display. Unlike static maps, you can zoom in and out, pan across areas, click on locations for more information, and even work with data overlays or visualizations—making the experience more dynamic and informative. One of the great things about tmap is that it lets you switch easily between static and interactive maps using tmap_mode(), so you can choose the view that best suits your analysis.\nBy modifying the code chunk in sub-section 2.6, the code chunks below build an interactive map using\n\npar(bg = '#fffbe8')\nregion_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\nregion_bbox &lt;- st_bbox(region_selected)\n\nstats &lt;- boxplot.stats(region_selected$DEPENDENCY)\noutlier_vals &lt;- stats$out\noutlier_sf &lt;- region_selected[region_selected$DEPENDENCY %in% outlier_vals, ]\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(region_selected, \n         bbox = region_bbox) +\n  tm_fill(\"DEPENDENCY\",\n          id = \"SUBZONE_N\",\n          popup.vars = c(\n            \"Name\" = \"SUBZONE_N\", \n            \"Dependency\" = \"DEPENDENCY\")) +\n  tm_borders() +\n  tm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2)\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\nThe interactive map above is far from satisfactory. While we want to encourage users to engage and explore the interactive by zooming in and out of the study area freely. But, users might lost in the cyberspace with too much freedom to zoom-in and zoom-out.\nTo address this issue, set_zoom_limits argument can be used to limit the map extend users can zooming in and out of the map areas as shown below.\n\npar(bg = '#fffbe8')\nregion_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\nregion_bbox &lt;- st_bbox(region_selected)\n\nstats &lt;- boxplot.stats(region_selected$DEPENDENCY)\noutlier_vals &lt;- stats$out\noutlier_sf &lt;- region_selected[region_selected$DEPENDENCY %in% outlier_vals, ]\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(region_selected, \n         bbox = region_bbox) +\n  tm_fill(\"DEPENDENCY\",\n          id = \"SUBZONE_N\",\n          popup.vars = c(\n            \"Name\" = \"SUBZONE_N\", \n            \"Dependency\" = \"DEPENDENCY\")) +\n  tm_borders() +\n  tm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2) +\n  tm_view(set_zoom_limits = c(12,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\"."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#b-importing-aspatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#b-importing-aspatial-data-into-r",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "3b) Importing Aspatial Data into R",
    "text": "3b) Importing Aspatial Data into R\nNext, we will import respopagesextod2024.csv file into RStudio and save the file into an tibble dataframe called popdata by using read_csv() function of readr package.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2024.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npopdata &lt;- popdata %&gt;%\n  mutate(Pop = as.numeric(Pop))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#g-complementing-thematic-map-with-statistical-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#g-complementing-thematic-map-with-statistical-chart",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "5g) Complementing Thematic Map with Statistical Chart",
    "text": "5g) Complementing Thematic Map with Statistical Chart\nMaps and statistical charts complement each other by visually representing different aspects of the same data, offering a more comprehensive understanding. Maps excel at showing spatial relationships and geographical patterns, while charts effectively display numerical data, trends, and comparisons. Combining both allows for a more insightful and engaging data narrative, especially when dealing with spatial data that also has quantifiable characteristics.\nWith tmap, statistical chart and be incorporate into the map visualisation by using fill.chat argument of map layers and legend chart feature as shown in the code chunk below.\n\npar(bg = '#fffbe8')\nmpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\") %&gt;%\n  tm_shape() +\n  tm_polygons(fill = \"DEPENDENCY\",\n              fill.scale = tm_scale_intervals(\n                style = \"quantile\", \n                values = \"brewer.greens\"),\n              fill.legend = tm_legend(),\n              fill.chart = tm_chart_box()) +\n  tm_borders() +\n  tm_layout(asp = 0.8)\n\n\n\n\n\n\n\n\nIn the code chunk below, We improve the visual representation further by highlighting and lebaling the outliers on the choropleth map.\n\npar(bg = '#fffbe8')\nmpsz_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\n\nstats &lt;- boxplot.stats(mpsz_selected$DEPENDENCY)\n\noutlier_vals &lt;- stats$out\n\noutlier_sf &lt;- mpsz_selected[mpsz_selected$DEPENDENCY %in% outlier_vals, ]\n\ntm_shape(mpsz_selected) +\n  tm_polygons(fill = \"DEPENDENCY\",\n          fill.scale = tm_scale_intervals(\n            style = \"quantile\", \n            values = \"brewer.blues\"),\n          fill.legend = tm_legend(),\n          fill.chart = tm_chart_box()) +\n  tm_borders(fill_alpha = 0.5) +\ntm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2) +\n  tm_text(\"SUBZONE_N\", col = \"red\", size = 0.7) +\n  tm_layout(asp = 0.8)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#h-creating-interactive-map",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01b.html#h-creating-interactive-map",
    "title": "Hands on Exercise 1b: Thematic Mapping and GeoVisualisation with R",
    "section": "5h) Creating Interactive Map**",
    "text": "5h) Creating Interactive Map**\nInteractive maps let users actively explore and interact with the data they display. Unlike static maps, you can zoom in and out, pan across areas, click on locations for more information, and even work with data overlays or visualizations—making the experience more dynamic and informative. One of the great things about tmap is that it lets you switch easily between static and interactive maps using tmap_mode(), so you can choose the view that best suits your analysis.\nBy modifying the code chunk in sub-section 2.6, the code chunks below build an interactive map using\n\npar(bg = '#fffbe8')\nregion_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\nregion_bbox &lt;- st_bbox(region_selected)\n\nstats &lt;- boxplot.stats(region_selected$DEPENDENCY)\noutlier_vals &lt;- stats$out\noutlier_sf &lt;- region_selected[region_selected$DEPENDENCY %in% outlier_vals, ]\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(region_selected, \n         bbox = region_bbox) +\n  tm_fill(\"DEPENDENCY\",\n          id = \"SUBZONE_N\",\n          popup.vars = c(\n            \"Name\" = \"SUBZONE_N\", \n            \"Dependency\" = \"DEPENDENCY\")) +\n  tm_borders() +\n  tm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2)\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\".\n\n\nThe interactive map above is far from satisfactory. While we want to encourage users to engage and explore the interactive by zooming in and out of the study area freely. But, users might lost in the cyberspace with too much freedom to zoom-in and zoom-out.\nTo address this issue, set_zoom_limits argument can be used to limit the map extend users can zooming in and out of the map areas as shown below.\n\npar(bg = '#fffbe8')\nregion_selected &lt;- mpsz_pop2024 %&gt;%\n  filter(REGION_N == \"CENTRAL REGION\")\nregion_bbox &lt;- st_bbox(region_selected)\n\nstats &lt;- boxplot.stats(region_selected$DEPENDENCY)\noutlier_vals &lt;- stats$out\noutlier_sf &lt;- region_selected[region_selected$DEPENDENCY %in% outlier_vals, ]\n\ntmap_mode(\"view\")\n\nℹ tmap mode set to \"view\".\n\ntm_shape(region_selected, \n         bbox = region_bbox) +\n  tm_fill(\"DEPENDENCY\",\n          id = \"SUBZONE_N\",\n          popup.vars = c(\n            \"Name\" = \"SUBZONE_N\", \n            \"Dependency\" = \"DEPENDENCY\")) +\n  tm_borders() +\n  tm_shape(outlier_sf) +\n  tm_borders(col = \"red\", lwd = 2) +\n  tm_view(set_zoom_limits = c(12,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nℹ tmap mode set to \"plot\"."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis (SPPA) is the evaluation of the pattern or distribution of a set of points on a surface. The points may represent:\n\nevents such as crimes, traffic accidents, or disease onsets, or\nbusiness services such as coffee shops/fast-food outlets or facilities such as childcare centres and eldercare centres.\n\nUsing suitable functions of spatstat to find the spatial point processes of childcare centers and perform two commonly used 1st-SPPA methods:\nThe specific questions we would like to answer are as follows:\n\nAre the childcare centres in Singapore randomly distributed throughout the country?\nIf the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#overview",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis (SPPA) is the evaluation of the pattern or distribution of a set of points on a surface. The points may represent:\n\nevents such as crimes, traffic accidents, or disease onsets, or\nbusiness services (e.g., coffee shops and fast-food outlets) or facilities such as childcare centres and eldercare centres.\n\nFirst-order Spatial Point Pattern Analysis (1st-SPPA) focuses on understanding the intensity or density of points across a study area. It examines how the distribution of points varies over space, essentially identifying trends or patterns in point density. This type of analysis deals with the individual locations of points and their distribution, without considering interactions between them.\nIn essence, 1st-SPPA helps answer questions such as:\n\nWhere are points most densely located within the study area?\nIs point density uniform, or does it vary across space?\nHow spread out is the point pattern?\n\nIn this chapter, you will gain hands-on experience with spatstat to perform two commonly used 1st-SPPA methods:\nThe specific questions we would like to answer are as follows:\n\nAre the childcare centres in Singapore randomly distributed throughout the country?\nIf the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#the-data",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.2 The data",
    "text": "4.2 The data\nTo provide answers to the questions above, two data sets will be used. They are:\n\nChild Care Services data from data.gov.sg, a point feature data providing both location and attribute information of childcare centres.\nMaster Plan 2019 Subzone Boundary (No Sea), a polygon feature data providing information of URA 2019 Master Plan Planning Subzone boundary data.\n\nBoth data sets are provided in kml and geojson format. Students are free to download their preferred data format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#installing-and-loading-the-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#installing-and-loading-the-r-packages",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.3 Installing and Loading the R packages",
    "text": "4.3 Installing and Loading the R packages\nIn this hands-on exercise, five R packages will be used, they are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, which has a wide range of useful functions for point pattern analysis. In this hands-on exercise, it will be used to perform 1st- and 2nd-order spatial point patterns analysis and derive kernel density estimation (KDE) layer.\nterra: The terra package is a modern spatial data analysis package designed to replace the raster package. It offers improved speed and efficiency when working with both raster and vector spatial data, particularly with large datasets. terra provides functionalities for creating, reading, manipulating, and writing raster and vector data, and it’s built on top of GDAL and PROJ libraries for enhanced performance. In this hands-on exercise, it will be used to convert image output generate by spatstat into terra format.\ntmap which provides functions for plotting cartographic quality static point patterns maps or interactive maps by using leaflet API.\nrvest for scraping (or harvesting) data from web pages\n\nUse the code chunk below to install and launch the five R packages.\n\npacman::p_load(sf, terra, spatstat, \n               tmap, rvest, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#importing-and-wrangling-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#importing-and-wrangling-geospatial-data-sets",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.4 Importing and Wrangling Geospatial Data Sets",
    "text": "4.4 Importing and Wrangling Geospatial Data Sets\nUse the code chunk below to import Master Plan 2019 Subzone (No Sea) data set into R environment.\n\nmpsz_sf &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\") %&gt;% \n  st_zm(drop = TRUE, what = \"ZM\") %&gt;% st_transform(crs = 3414)\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex02\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nNext, build a function called extract_kml_field for extracting REGION_N, PLN_AREA_N, SUBZONE_N, SUBZONE_C from Description field by using the code chunk below.\n\nextract_kml_field &lt;- function(html_text, field_name) {\n  if (is.na(html_text) || html_text == \"\") return(NA_character_)\n  \n  page &lt;- read_html(html_text)\n  rows &lt;- page %&gt;% html_elements(\"tr\")\n  \n  value &lt;- rows %&gt;%\n    keep(~ html_text2(html_element(.x, \"th\")) == field_name) %&gt;%\n    html_element(\"td\") %&gt;%\n    html_text2()\n  \n  if (length(value) == 0) NA_character_ else value\n}\n\n\nmpsz_sf &lt;- mpsz_sf %&gt;%\n  mutate(\n    REGION_N = map_chr(Description, extract_kml_field, \"REGION_N\"),\n    PLN_AREA_N = map_chr(Description, extract_kml_field, \"PLN_AREA_N\"),\n    SUBZONE_N = map_chr(Description, extract_kml_field, \"SUBZONE_N\"),\n    SUBZONE_C = map_chr(Description, extract_kml_field, \"SUBZONE_C\")\n  ) %&gt;%\n  select(-Name, -Description) %&gt;%\n  relocate(geometry, .after = last_col())\n\n\nmpsz_cl &lt;- mpsz_sf %&gt;%\n  filter(SUBZONE_N != \"SOUTHERN GROUP\",\n         PLN_AREA_N != \"WESTERN ISLANDS\",\n         PLN_AREA_N != \"NORTH-EASTERN ISLANDS\")\n\n\nwrite_rds(mpsz_cl, \n          \"data/mpsz_cl.rds\")\n\nNext, code chunk below will be used to import the childcare Service data downloaded from data.gov.sg into R environment as sf data frame called chilcare_sf. The Simple Feature Geometry (sfg) of this geospatial data layer if\n\nchildcare_sf &lt;- st_read(\"data/ChildCareServices.kml\") %&gt;% \n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `CHILDCARE' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex02\\data\\ChildCareServices.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n4.4.1 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\nDIY\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare an interactive point symbol map by using the code chunk below.\n\ntmap_mode('view')\n\nℹ tmap mode set to \"view\".\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\nRegistered S3 method overwritten by 'jsonify':\n  method     from    \n  print.json jsonlite\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nℹ tmap mode set to \"plot\"."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#geospatial-data-wrangling",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5 Geospatial Data wrangling",
    "text": "4.5 Geospatial Data wrangling\nspatstat relies on its own specific data structures like ppp (planar point pattern) for point data and owin for observation windows. In this section, you will learn how to convert sf (Simple Features) objects into spatstat ppp and owin object.\n\n4.5.1 Converting sf data frames to ppp class\nspatstat requires the point event data in ppp object form. The code chunk below uses [as.ppp()] of spatstat package to convert childcare_sf to ppp format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nNext, class() of Base R will be used to verify the object class of childcare_ppp.\n\nclass(childcare_ppp)\n\n[1] \"ppp\"\n\n\nGreat, it is in ppp object class!\nYou can take a quick look at the summary statistics of the newly converted ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nMark variables: Name, Description\nSummary:\n     Name           Description       \n Length:1925        Length:1925       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units\n\n\n\n\n4.5.2 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below, as.owin() of spatstat is used to covert mpsz_sf into owin object of spatstat.\n\nsg_owin &lt;- as.owin(mpsz_cl)\n\nAgain, class() will be used to verify the object class of sg_owin.\n\nclass(sg_owin)\n\n[1] \"owin\"\n\n\nThe result above confirmed that sg_owin is indeed in owin object.\nsg_owin object can be displayed by using plot() function.\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\n\n\n4.5.3 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nchildcareSG_ppp\n\nMarked planar point pattern: 1925 points\nMark variables: Name, Description \nwindow: polygonal boundary\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#clark-evan-test-for-nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#clark-evan-test-for-nearest-neighbour-analysis",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.6 Clark-Evan Test for Nearest Neighbour Analysis",
    "text": "4.6 Clark-Evan Test for Nearest Neighbour Analysis\nNearest Neighbor Analysis (NNA) is a spatial statistics method that calculates the average distance between each point and its closest neighbor to determine if a pattern of points is clustered, dispersed, or randomly distributed.\nClark-Evans test is a specific statistical method used within NNA to quantify whether a point pattern is clustered, random, or uniformly spaced, using the Clark-Evans aggregation index (R) to describe this pattern. NNA provides a numerical value that describes the degree of clustering or regularity, and the Clark-Evans test calculates a specific index (R) for this purpose\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of spatstat.explore package.\nThe test hypotheses are:\nHo = The distribution of childcare services are randomly distributed.\nH1= The distribution of childcare services are not randomly distributed.\nThe 95% confident interval will be used.\n\n4.6.1 Perform the Clark-Evans test without CSR\nclarkevans.test() of spatstat.explore package support two Clark-Evans test, namely: without CRS and with CRS. In the code chunk below, Clark-Evans test without CSR method is used.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"))\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nDIY\nDraw statistical conclusion from the test result.\n\nProvide business communication from the statistical analysis.\n\n\n\n4.6.2 Perform the Clark-Evans test with CSR\nIn the code chunk below, the argument method = “MonteCarlo” is used. In this case, the p-value for the test is computed by comparing the observed value of R to the results obtained from nsim (i.e. 39, 99, 999) simulated realisations of Complete Spatial Randomness conditional on the observed number of points.\n\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                method=\"MonteCarlo\",\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value = 0.01\nalternative hypothesis: clustered (R &lt; 1)\n\n\n\nDIY Draw statistical conclusion from the test result.\nProvide business communication from the statistical analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#kernel-density-estimation-method",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#kernel-density-estimation-method",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7 Kernel Density Estimation Method",
    "text": "4.7 Kernel Density Estimation Method\nKernel Density Estimation (KDE) is a valuable tool for visualising and analyzing first-order spatial point patterns. It is widely considered a method within Exploratory Spatial Data Analysis (ESDA) because it’s used to visualize and understand spatial data patterns by transforms discrete point data (like locations of childcare service, crime incidents or disease cases) into continuous density surfaces that reveal clusters and variations in event occurrences, without making prior assumptions about data distribution. It helps to begin understanding data distribution, identify hotspots, and explore relationships between spatial variables before performing more rigorous analysis.\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n4.7.1 Working with automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\nkde_SG_diggle &lt;- density(\n  childcareSG_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel=\"gaussian\") \n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_SG_diggle)\n\n\n\n\n\n\n\n\nIn the code chunk below, summary() of Base R is used to print the summary report of the\n\nsummary(kde_SG_diggle)\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2667.538, 55941.94] x [21448.47, 50256.33] units\ndimensions of each pixel: 416 x 225.0614 units\nImage is defined on a subset of the rectangular grid\nSubset area = 669941961.12249 square units\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-6.584123e-21, 3.063698e-05]\n    integral = 1927.788\n    mean = 2.877545e-06\n\n\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n295.9712 \n\n\n\n\n\n4.7.2 Rescalling KDE values\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp_km &lt;- rescale.ppp(\n  childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG_km &lt;- density(childcareSG_ppp_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nNext, plot() is used to plot the kde object as shown below.\n\nplot(kde_childcareSG_km)\n\n\n\n\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend).\n\n\n4.7.3 Working with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp_km)\n\n   sigma \n4.357209 \n\n\n\nbw.scott(childcareSG_ppp_km)\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\nbw.ppl(childcareSG_ppp_km)\n\n   sigma \n0.378997 \n\n\n\nbw.diggle(childcareSG_ppp_km)\n\n    sigma \n0.2959712 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because past experience shown that it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp_km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG_km, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n4.7.4 Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#fixed-and-adaptive-kde",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.8 Fixed and Adaptive KDE",
    "text": "4.8 Fixed and Adaptive KDE\n\n4.8.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp_km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_fb &lt;- density(childcareSG_ppp_km,\n                              sigma=0.6, \n                              edge=TRUE,\n                              kernel=\"gaussian\")\nplot(kde_childcareSG_fb)\n\n\n\n\n\n\n\n\n\n\n4.8.2 Computing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, you will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_ab &lt;- adaptive.density(\n  childcareSG_ppp_km, \n  method=\"kernel\")\nplot(kde_childcareSG_ab)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG_fb, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_ab, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#plotting-cartographic-quality-kde-map",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#plotting-cartographic-quality-kde-map",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.9 Plotting cartographic quality KDE map",
    "text": "4.9 Plotting cartographic quality KDE map\n\n4.9.1 Converting gridded output into raster\nNext, we will convert the im kernal density objects into SpatRaster object by using rast() of terra package.\n\nkde_childcareSG_bw_terra &lt;- rast(kde_childcareSG_km)\n\nAgain, class() is used to verify if kde_childcareSG_bw_terra data are belong to SpatRaster class.\n\nclass(kde_childcareSG_bw_terra)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\n\nYes, it is indeed in SpatRaster class.\nLet us take a look at the properties of kde_childcareSG_bw_terra .\n\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \ndimensions  : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -5.824417e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\nNotice that the crs property is empty.\n\n\n4.9.2 Assigning projection systems\nIn code chunk below, crs() of terra is used to assign the CRS information on kde_childcareSG_bw_terra layer.\n\ncrs(kde_childcareSG_bw_terra) &lt;- \"EPSG:3414\"\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer\n\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \ndimensions  : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. : SVY21 / Singapore TM (EPSG:3414) \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -5.824417e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\nNotice that the coordicates reference (i.e. coord. ref.) is in SVY21 now.\n\n\n4.9.3 Plotting KDE map with tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_terra) + \n  tm_raster(col.scale = \n              tm_scale_continuous(\n                values = \"viridis\"),\n            col.legend = tm_legend(\n            title = \"Density values\",\n            title.size = 0.7,\n            text.size = 0.7,\n            bg.color = \"white\",\n            bg.alpha = 0.7,\n            position = tm_pos_in(\n              \"right\", \"bottom\"),\n            frame = TRUE)) +\n  tm_graticules(labels.size = 0.7) +\n  tm_compass() +\n  tm_layout(scale = 1.0)\n\n[plot mode] legend/component: Some components or legends are too \"high\" and are\ntherefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “layer.1” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#first-order-sppa-at-the-planning-subzone-level",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#first-order-sppa-at-the-planning-subzone-level",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.10 First Order SPPA at the Planning Subzone Level",
    "text": "4.10 First Order SPPA at the Planning Subzone Level\nIn this section, we would like to further our analysis at the planning area level. For simplicity reason, we will focus on Punggol, Tampines Chua Chu Kand and Jurong West planning areas\n\n4.10.1 Geospatial data wrangling\n\n4.10.1.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nIt is always a good practice to review the extracted areas. The code chunk below will be used to plot the extracted planning areas.\n\npar(mfrow=c(2,2))\nplot(st_geometry(pg), main = \"Ponggol\")\nplot(st_geometry(tm), main = \"Tampines\")\nplot(st_geometry(ck), main = \"Choa Chu Kang\")\nplot(st_geometry(jw), main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n4.10.1.2 Creating owin object\nNow, we will convert these sf objects into owin objects that is required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n4.10.1.3 Combining point events object and owin object\n\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(unmark(childcare_pg_ppp.km), \n  main=\"Punggol\")\nplot(unmark(childcare_tm_ppp.km), \n  main=\"Tampines\")\nplot(unmark(childcare_ck_ppp.km), \n  main=\"Choa Chu Kang\")\nplot(unmark(childcare_jw_ppp.km), \n  main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\n4.10.2 Clark and Evans Test\n\n4.10.2.1 Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.84097, p-value = 0.008866\nalternative hypothesis: two-sided\n\n\n\n\n4.10.2.2 Tampines planning area\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.66817, p-value = 6.58e-12\nalternative hypothesis: two-sided\n\n\n\n\n\n4.10.3 Computing KDE surfaces by planning area\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a.-mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a.-mapping-the-geospatial-data-sets",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4a. Mapping the geospatial data sets",
    "text": "4a. Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\nDIY\n\nmpsz_cl &lt;- read_rds(\"data/mpsz_cl.rds\")\nchildcare_sf &lt;- st_read(\"data/ChildCareServices.kml\") %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = st_crs(mpsz_cl))  \n\nReading layer `CHILDCARE' from data source \n  `C:\\privatejet\\ShanmugaPriyaRajasekaran\\ISSS626\\Hands-on_Ex\\Hands-on_Ex02\\data\\ChildCareServices.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nggplot() +\n  geom_sf(data = mpsz_cl, fill = \"gray\", color = \"black\", size = 0.2) +\n  geom_sf(data = childcare_sf, color = \"black\", size = 1.2, alpha = 0.7) +\n  labs(title = \"Childcare Services Across Singapore Subzones\",\n       subtitle = \"All layers aligned to EPSG:3414 (SVY21)\",\n       caption = \"Source: URA Master Plan & Data.gov.sg\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can also prepare an interactive point symbol map by using the code chunk below.\n\ntmap_mode('view')\n\nℹ tmap mode set to \"view\".\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\nRegistered S3 method overwritten by 'jsonify':\n  method     from    \n  print.json jsonlite\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nℹ tmap mode set to \"plot\"."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-converting-sf-data-frames-to-ppp-class",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-converting-sf-data-frames-to-ppp-class",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5a) Converting sf data frames to ppp class",
    "text": "5a) Converting sf data frames to ppp class\nspatstat requires the point event data in ppp object form. The code chunk below uses [as.ppp()] of spatstat package to convert childcare_sf to ppp format.\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nNext, class() of Base R will be used to verify the object class of childcare_ppp.\n\nclass(childcare_ppp)\n\n[1] \"ppp\"\n\n\nLet’s check the summary statistics of the newly converted ppp object.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1925 points\nAverage intensity 2.417323e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nMark variables: Name, Description\nSummary:\n     Name           Description       \n Length:1925        Length:1925       \n Class :character   Class :character  \n Mode  :character   Mode  :character  \n\nWindow: rectangle = [11810.03, 45404.24] x [25596.33, 49300.88] units\n                    (33590 x 23700 units)\nWindow area = 796335000 square units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-creating-owin-object",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5b) Creating owin object",
    "text": "5b) Creating owin object\nIt’s a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below, as.owin() of spatstat is used to covert mpsz_sf into owin object of spatstat.\n\nsg_owin &lt;- as.owin(mpsz_cl)\n\nAgain, class() will be used to verify the object class of sg_owin.\n\nclass(sg_owin)\n\n[1] \"owin\"\n\n\nThe result above confirmed that sg_owin is indeed in owin object.\n\nplot(sg_owin)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#c-combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#c-combining-point-events-object-and-owin-object",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5c) Combining point events object and owin object",
    "text": "5c) Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nchildcareSG_ppp\n\nMarked planar point pattern: 1925 points\nMark variables: Name, Description \nwindow: polygonal boundary\nenclosing rectangle: [2667.54, 55941.94] x [21448.47, 50256.33] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-perform-the-clark-evans-test-without-csr",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-perform-the-clark-evans-test-without-csr",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6a) Perform the Clark-Evans test without CSR",
    "text": "6a) Perform the Clark-Evans test without CSR\nclarkevans.test() of spatstat.explore package support two Clark-Evans test, namely: without CRS and with CRS. In the code chunk below, Clark-Evans test without CSR method is used.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"))\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nStatistical conclusion: The Clark–Evans result (R = 0.535, p &lt; 2.2e-16) gives clear, strong evidence that childcare locations are clustered, not random.\nBusiness takeaway: Childcare centres in Singapore are concentrated in a few pockets, leaving other areas relatively underserved. This points to possible over-supply in some neighbourhoods and gaps elsewhere; planners and providers should reassess site choices to improve coverage and equity."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-perform-the-clark-evans-test-with-csr",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-perform-the-clark-evans-test-with-csr",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6b) Perform the Clark-Evans test with CSR",
    "text": "6b) Perform the Clark-Evans test with CSR\nIn the code chunk below, the argument method = “MonteCarlo” is used. In this case, the p-value for the test is computed by comparing the observed value of R to the results obtained from nsim (i.e. 39, 99, 999) simulated realisations of Complete Spatial Randomness conditional on the observed number of points.\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                method=\"MonteCarlo\",\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.53532, p-value = 0.01\nalternative hypothesis: clustered (R &lt; 1)\n\n\n[Statistical Conclusion:] Clark–Evans (with Monte Carlo) gives R = 0.53532 and p = 0.01. Since R &lt; 1 and p is small, we reject random placement—the childcare locations are significantly clustered.\n[Business Conclusion:] Childcare centres are bunched in a few areas instead of being evenly spread. Some neighbourhoods likely have more centres than needed, while others are short. Planners and providers should rebalance by adding or expanding in underserved zones to improve citywide access."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-working-with-automatic-bandwidth-selection-method",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-working-with-automatic-bandwidth-selection-method",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7a) Working with automatic bandwidth selection method",
    "text": "7a) Working with automatic bandwidth selection method\n\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\nkde_SG_diggle &lt;- density(\n  childcareSG_ppp,\n  sigma=bw.diggle,\n  edge=TRUE,\n  kernel=\"gaussian\") \n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_SG_diggle)\n\n\n\n\n\n\n\n\n\nsummary(kde_SG_diggle)\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2667.538, 55941.94] x [21448.47, 50256.33] units\ndimensions of each pixel: 416 x 225.0614 units\nImage is defined on a subset of the rectangular grid\nSubset area = 669941961.12249 square units\nSubset area fraction = 0.437\nPixel values (inside window):\n    range = [-6.584123e-21, 3.063698e-05]\n    integral = 1927.788\n    mean = 2.877545e-06\n\n\nRetrieve the bandwidth used to compute the kde layer\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n295.9712"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-rescalling-kde-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-rescalling-kde-values",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7b) Rescalling KDE values",
    "text": "7b) Rescalling KDE values\nIn the code chunk below, rescale.ppp() is used to covert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp_km &lt;- rescale.ppp(\n  childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG_km &lt;- density(childcareSG_ppp_km,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                              kernel=\"gaussian\")\n\nNext, plot() is used to plot the kde object as shown below.\n\nplot(kde_childcareSG_km)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#c-working-with-different-automatic-badwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#c-working-with-different-automatic-badwidth-methods",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7c) Working with different automatic badwidth methods",
    "text": "7c) Working with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp_km)\n\n   sigma \n4.357209 \n\n\n\nbw.scott(childcareSG_ppp_km)\n\n sigma.x  sigma.y \n2.159749 1.396455 \n\n\n\nbw.ppl(childcareSG_ppp_km)\n\n   sigma \n0.378997 \n\n\n\nbw.diggle(childcareSG_ppp_km)\n\n    sigma \n0.2959712 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because past experience shown that it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp_km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG_km, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#d-working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#d-working-with-different-kernel-methods",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7d) Working with different kernel methods",
    "text": "7d) Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp_km, \n             sigma=0.2959712, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-computing-kde-by-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-computing-kde-by-using-fixed-bandwidth",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "8a) Computing KDE by using fixed bandwidth",
    "text": "8a) Computing KDE by using fixed bandwidth\nWe will compute a KDE layer by defining a bandwidth of 600 meter and the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp_km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_fb &lt;- density(childcareSG_ppp_km,\n                              sigma=0.6, \n                              edge=TRUE,\n                              kernel=\"gaussian\")\nplot(kde_childcareSG_fb)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "8b) Computing KDE by using adaptive bandwidth",
    "text": "8b) Computing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\n\nkde_childcareSG_ab &lt;- adaptive.density(\n  childcareSG_ppp_km, \n  method=\"kernel\")\nplot(kde_childcareSG_ab)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG_fb, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_ab, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-converting-gridded-output-into-raster",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-converting-gridded-output-into-raster",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "9a) Converting gridded output into raster",
    "text": "9a) Converting gridded output into raster\nWe will convert the im kernal density objects into SpatRaster object by using rast() of terra package.\n\nkde_childcareSG_bw_terra &lt;- rast(kde_childcareSG_km)\n\nVerify if kde_childcareSG_bw_terra data are belong to SpatRaster class.\n\nclass(kde_childcareSG_bw_terra)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\n\nYes, it is indeed in SpatRaster class.\nLet us take a look at the properties of kde_childcareSG_bw_terra .\n\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \ndimensions  : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -5.824417e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\nNotice that the crs property is empty."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-assigning-projection-systems",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-assigning-projection-systems",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "9b) Assigning projection systems",
    "text": "9b) Assigning projection systems\ncrs() of terra is used to assign the CRS information on kde_childcareSG_bw_terra layer.\n\ncrs(kde_childcareSG_bw_terra) &lt;- \"EPSG:3414\"\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer\n\nkde_childcareSG_bw_terra\n\nclass       : SpatRaster \ndimensions  : 128, 128, 1  (nrow, ncol, nlyr)\nresolution  : 0.4162063, 0.2250614  (x, y)\nextent      : 2.667538, 55.94194, 21.44847, 50.25633  (xmin, xmax, ymin, ymax)\ncoord. ref. : SVY21 / Singapore TM (EPSG:3414) \nsource(s)   : memory\nname        :         lyr.1 \nmin value   : -5.824417e-15 \nmax value   :  3.063698e+01 \nunit        :            km \n\n\nNotice that the coordicates reference (i.e. coord. ref.) is in SVY21 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#c-plotting-kde-map-with-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#c-plotting-kde-map-with-tmap",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "9c) Plotting KDE map with tmap",
    "text": "9c) Plotting KDE map with tmap\nFinally, we will display the raster in cartographic quality map\n\ntm_shape(kde_childcareSG_bw_terra) + \n  tm_raster(col.scale = \n              tm_scale_continuous(\n                values = \"viridis\"),\n            col.legend = tm_legend(\n            title = \"Density values\",\n            title.size = 0.7,\n            text.size = 0.7,\n            bg.color = \"white\",\n            bg.alpha = 0.7,\n            position = tm_pos_in(\n              \"right\", \"bottom\"),\n            frame = TRUE)) +\n  tm_graticules(labels.size = 0.7) +\n  tm_compass() +\n  tm_layout(scale = 1.0)\n\n[plot mode] legend/component: Some components or legends are too \"high\" and are\ntherefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n\n\n\n\n\n\n\n\n\nThe raster values are encoded explicitly onto the raster pixel using the values in “layer.1” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#a-geospatial-data-wrangling",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "10a) Geospatial data wrangling",
    "text": "10a) Geospatial data wrangling\n\n10a.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_cl %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nIt is always a good practice to review the extracted areas. The code chunk below will be used to plot the extracted planning areas.\n\npar(mfrow=c(2,2))\nplot(st_geometry(pg), main = \"Ponggol\")\nplot(st_geometry(tm), main = \"Tampines\")\nplot(st_geometry(ck), main = \"Choa Chu Kang\")\nplot(st_geometry(jw), main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n10a.2 Creating owin object\nNow, we will convert these sf objects into owin objects\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n10a.3 Combining point events object and owin object\n\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]\n\nNext, rescale.ppp() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(unmark(childcare_pg_ppp.km), \n  main=\"Punggol\")\nplot(unmark(childcare_tm_ppp.km), \n  main=\"Tampines\")\nplot(unmark(childcare_ck_ppp.km), \n  main=\"Choa Chu Kang\")\nplot(unmark(childcare_jw_ppp.km), \n  main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-clark-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02a.html#b-clark-and-evans-test",
    "title": "Hands on Exercise 2a: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "10b) Clark and Evans Test",
    "text": "10b) Clark and Evans Test\n\n10b.1 Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.84097, p-value = 0.008866\nalternative hypothesis: two-sided\n\n\n\n\n10b.2 Tampines planning area\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.66817, p-value = 6.58e-12\nalternative hypothesis: two-sided\n\n\n\n\n10b.3 Computing KDE surfaces by planning area\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html",
    "title": "Hands on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Second-order spatial point pattern analysis examines the spatial relationships between points in a pattern, specifically focusing on how the presence of one point influences the location of others. It goes beyond simply describing the overall density of points (first-order effects) by investigating clustering, dispersion, or randomness at various spatial scales.\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#a.1-choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#a.1-choa-chu-kang-planning-area",
    "title": "Hands on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5a.1 Choa Chu Kang planning area",
    "text": "5a.1 Choa Chu Kang planning area\n\n5a.1.1 Computing G-function estimation\n\nset.seed(1234)\n\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\n\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n5a.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n5b) Tampines planning area\n\n5.6.2.1 Computing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n5.6.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-f-function",
    "title": "Hands on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.7 Analysing Spatial Point Process Using F-Function",
    "text": "5.7 Analysing Spatial Point Process Using F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, you will learn how to compute F-function estimation by using Fest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n5.7.1 Choa Chu Kang planning area\n\n5.7.1.1 Computing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\n\n5.7.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n5.7.3 Tampines planning area\n\n5.7.3.1 Computing F-function estimation\nMonte Carlo test with F-fucntion\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n5.7.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.8 Analysing Spatial Point Process Using K-Function",
    "text": "5.8 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n5.8.1 Choa Chu Kang planning area\n\n5.8.1.1 Computing K-fucntion estimate\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n5.8.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n5.8.2 Tampines planning area\n\n5.8.2.1 Computing K-fucntion estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n5.8.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02b.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands on Exercise 2b: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.9 Analysing Spatial Point Process Using L-Function",
    "text": "5.9 Analysing Spatial Point Process Using L-Function\nIn this section, you will learn how to compute L-function estimation by using Lest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n5.9.1 Choa Chu Kang planning area\n\n5.9.1.1 Computing L Fucntion estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n5.9.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n5.9.2 Tampines planning area\n\n5.9.2.1 Computing L-fucntion estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n5.9.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\nThen, plot the model output by using the code chun below.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  }
]